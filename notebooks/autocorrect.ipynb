{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten words in the text are:['the', 'project', 'gutenberg', 'ebook', 'of', 'moby', 'dick', 'or', 'the', 'whale']\n",
      "Total Unique words are 17647.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textdistance\n",
    "import re\n",
    "from collections import Counter\n",
    "words = []\n",
    "with open('../data/autocorrect/book.txt', 'r') as f:\n",
    "    file_name_data = f.read()\n",
    "    file_name_data=file_name_data.lower()\n",
    "    words = re.findall('\\w+',file_name_data)\n",
    "\n",
    "V = set(words)\n",
    "print(f\"Top ten words in the text are:{words[0:10]}\")\n",
    "print(f\"Total Unique words are {len(V)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 14703), ('of', 6742), ('and', 6517), ('a', 4799), ('to', 4707), ('in', 4238), ('that', 3081), ('it', 2534), ('his', 2530), ('i', 2120)]\n"
     ]
    }
   ],
   "source": [
    "word_freq = {}  \n",
    "word_freq = Counter(words)\n",
    "print(word_freq.most_common()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = {}     \n",
    "Total = sum(word_freq.values())    \n",
    "for k in word_freq.keys():\n",
    "    probs[k] = word_freq[k]/Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_autocorrect(input_word):\n",
    "    input_word = input_word.lower()\n",
    "    if input_word in V:\n",
    "            return('Your word seems to be correct')\n",
    "    else:\n",
    "        sim = [1-(textdistance.Jaccard(qval=2).distance(v,input_word)) for v in word_freq.keys()]\n",
    "        df = pd.DataFrame.from_dict(probs, orient='index').reset_index()\n",
    "        df = df.rename(columns={'index':'Word', 0:'Prob'})\n",
    "        df['Similarity'] = sim\n",
    "        output = df.sort_values(['Similarity', 'Prob'], ascending=False).head()\n",
    "        return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Prob</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>ram</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11220</th>\n",
       "      <td>rammed</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>grammar</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>crammed</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13761</th>\n",
       "      <td>ramming</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word      Prob  Similarity\n",
       "271        ram  0.000036    0.666667\n",
       "11220   rammed  0.000009    0.600000\n",
       "451    grammar  0.000009    0.500000\n",
       "3469   crammed  0.000004    0.500000\n",
       "13761  ramming  0.000004    0.500000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_autocorrect(\"ramm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacy contextualSpellCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import contextualSpellCheck\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "contextualSpellCheck.add_to_pipe(nlp)\n",
    "\n",
    "def contextual_spellcheck(input_str: str):\n",
    "    doc = nlp(input_str)\n",
    "\n",
    "    return doc._.performed_spellCheck, doc._.suggestions_spellCheck, doc._.score_spellCheck, doc._.outcome_spellCheck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\x01',\n",
       " '\\x02',\n",
       " '\\x03',\n",
       " '\\x04',\n",
       " '\\x05',\n",
       " '\\x06',\n",
       " '\\x07',\n",
       " '\\x08',\n",
       " '\\t',\n",
       " '\\t\\t',\n",
       " '\\t\\x0b',\n",
       " '\\t\\x0c',\n",
       " '\\t\\r',\n",
       " '\\t\\x1c',\n",
       " '\\t\\x1d',\n",
       " '\\t\\x1e',\n",
       " '\\t\\x1f',\n",
       " '\\t ',\n",
       " '\\t\\x85',\n",
       " '\\t\\x85\\u1680',\n",
       " '\\t\\xa0',\n",
       " '\\t\\u1680',\n",
       " '\\t\\u2001',\n",
       " '\\t\\u2005',\n",
       " '\\t\\u2006',\n",
       " '\\t\\u2007',\n",
       " '\\t\\u2008',\n",
       " '\\t\\u2009',\n",
       " '\\t\\u200a',\n",
       " '\\t\\u2028',\n",
       " '\\t\\u205f',\n",
       " '\\t\\u3000',\n",
       " '\\n',\n",
       " '\\n\\t',\n",
       " '\\n\\x0b',\n",
       " '\\n\\r',\n",
       " '\\n\\r\\t',\n",
       " '\\n\\x1c',\n",
       " '\\n ',\n",
       " '\\n\\u1680',\n",
       " '\\n\\u2001',\n",
       " '\\n\\u2002',\n",
       " '\\n\\u2003',\n",
       " '\\n\\u2004',\n",
       " '\\n\\u2005',\n",
       " '\\n\\u2006',\n",
       " '\\n\\u2007',\n",
       " '\\n\\u2008',\n",
       " '\\n\\u2009',\n",
       " '\\n\\u200a',\n",
       " '\\n\\u2029',\n",
       " '\\n\\u202f',\n",
       " '\\n\\u205f',\n",
       " '\\n\\u3000',\n",
       " '\\x0b',\n",
       " '\\x0b\\n',\n",
       " '\\x0b\\x0b',\n",
       " '\\x0b\\x0c',\n",
       " '\\x0b\\r',\n",
       " '\\x0b ',\n",
       " '\\x0b\\x85',\n",
       " '\\x0b\\xa0',\n",
       " '\\x0b\\u1680',\n",
       " '\\x0b\\u2001',\n",
       " '\\x0b\\u2002',\n",
       " '\\x0b\\u2003',\n",
       " '\\x0b\\u2005',\n",
       " '\\x0b\\u2005\\u2000',\n",
       " '\\x0b\\u2006',\n",
       " '\\x0b\\u2007',\n",
       " '\\x0b\\u2008',\n",
       " '\\x0b\\u200a',\n",
       " '\\x0b\\u2028',\n",
       " '\\x0b\\u2029',\n",
       " '\\x0b\\u202f',\n",
       " '\\x0b\\u205f\\u2007',\n",
       " '\\x0b\\u3000',\n",
       " '\\x0c',\n",
       " '\\x0c\\t',\n",
       " '\\x0c\\n',\n",
       " '\\x0c\\r',\n",
       " '\\x0c\\x1d',\n",
       " '\\x0c\\x1f',\n",
       " '\\x0c ',\n",
       " '\\x0c\\x85',\n",
       " '\\x0c\\xa0',\n",
       " '\\x0c\\u1680',\n",
       " '\\x0c\\u2001',\n",
       " '\\x0c\\u2002 ',\n",
       " '\\x0c\\u2003',\n",
       " '\\x0c\\u2007',\n",
       " '\\x0c\\u2008',\n",
       " '\\x0c\\u200a',\n",
       " '\\x0c\\u200a\\u2004',\n",
       " '\\x0c\\u2028',\n",
       " '\\x0c\\u2028\\u200a\\u2004',\n",
       " '\\x0c\\u2029',\n",
       " '\\x0c\\u202f',\n",
       " '\\x0c\\u205f',\n",
       " '\\x0c\\u3000',\n",
       " '\\r',\n",
       " '\\r\\t',\n",
       " '\\r\\n',\n",
       " '\\r\\x0b',\n",
       " '\\r\\x0c',\n",
       " '\\r\\x1c',\n",
       " '\\r ',\n",
       " '\\r\\x85',\n",
       " '\\r\\xa0',\n",
       " '\\r\\u1680',\n",
       " '\\r\\u2000',\n",
       " '\\r\\u2001',\n",
       " '\\r\\u2002',\n",
       " '\\r\\u2004',\n",
       " '\\r\\u2005',\n",
       " '\\r\\u2007',\n",
       " '\\r\\u2008',\n",
       " '\\r\\u2028',\n",
       " '\\r\\u2029',\n",
       " '\\r\\u205f',\n",
       " '\\r\\u3000',\n",
       " '\\x0f',\n",
       " '\\x13',\n",
       " '\\x14',\n",
       " '\\x1c',\n",
       " '\\x1c\\x0c',\n",
       " '\\x1c\\r',\n",
       " '\\x1c\\x1d',\n",
       " '\\x1c\\x1e',\n",
       " '\\x1c\\x1f',\n",
       " '\\x1c ',\n",
       " '\\x1c\\x85',\n",
       " '\\x1c\\xa0',\n",
       " '\\x1c\\u1680',\n",
       " '\\x1c\\u2000',\n",
       " '\\x1c\\u2001',\n",
       " '\\x1c\\u2003',\n",
       " '\\x1c\\u2006',\n",
       " '\\x1c\\u2007',\n",
       " '\\x1c\\u2008',\n",
       " '\\x1c\\u2008\\u2000',\n",
       " '\\x1c\\u2009',\n",
       " '\\x1c\\u2028',\n",
       " '\\x1c\\u202f',\n",
       " '\\x1c\\u205f',\n",
       " '\\x1c\\u3000',\n",
       " '\\x1d',\n",
       " '\\x1d\\n',\n",
       " '\\x1d\\x0b',\n",
       " '\\x1d\\r',\n",
       " '\\x1d\\x1c',\n",
       " '\\x1d\\x1d',\n",
       " '\\x1d\\x1e',\n",
       " '\\x1d\\x1f',\n",
       " '\\x1d ',\n",
       " '\\x1d\\u2000',\n",
       " '\\x1d\\u2002',\n",
       " '\\x1d\\u2003',\n",
       " '\\x1d\\u2005',\n",
       " '\\x1d\\u2006',\n",
       " '\\x1d\\u2007',\n",
       " '\\x1d\\u2009',\n",
       " '\\x1d\\u200a',\n",
       " '\\x1d\\u200a\\u2000',\n",
       " '\\x1d\\u2029',\n",
       " '\\x1d\\u202f',\n",
       " '\\x1d\\u205f',\n",
       " '\\x1d\\u3000',\n",
       " '\\x1e',\n",
       " '\\x1e\\n',\n",
       " '\\x1e\\x0c',\n",
       " '\\x1e\\x1d',\n",
       " '\\x1e\\x1f',\n",
       " '\\x1e ',\n",
       " '\\x1e\\x85',\n",
       " '\\x1e\\xa0',\n",
       " '\\x1e\\u1680',\n",
       " '\\x1e\\u2000',\n",
       " '\\x1e\\u2003',\n",
       " '\\x1e\\u2004',\n",
       " '\\x1e\\u2008',\n",
       " '\\x1e\\u2009',\n",
       " '\\x1e\\u200a',\n",
       " '\\x1e\\u2028',\n",
       " '\\x1e\\u2029',\n",
       " '\\x1e\\u202f',\n",
       " '\\x1e\\u3000',\n",
       " '\\x1f',\n",
       " '\\x1f\\t',\n",
       " '\\x1f\\n',\n",
       " '\\x1f\\r',\n",
       " '\\x1f\\x1c',\n",
       " '\\x1f\\x1d',\n",
       " '\\x1f ',\n",
       " '\\x1f\\xa0',\n",
       " '\\x1f\\u2000',\n",
       " '\\x1f\\u2001',\n",
       " '\\x1f\\u2004',\n",
       " '\\x1f\\u2006',\n",
       " '\\x1f\\u2007',\n",
       " '\\x1f\\u2008',\n",
       " '\\x1f\\u2009',\n",
       " '\\x1f\\u200a',\n",
       " '\\x1f\\u2028',\n",
       " '\\x1f\\u2029\\u2009',\n",
       " '\\x1f\\u202f',\n",
       " '\\x1f\\u205f',\n",
       " '\\x1f\\u3000',\n",
       " ' ',\n",
       " ' \\n',\n",
       " ' \\x0b',\n",
       " ' \\x0c',\n",
       " ' \\r',\n",
       " ' \\x1c',\n",
       " ' \\x1d',\n",
       " ' \\x1e',\n",
       " ' \\x1f',\n",
       " '  ',\n",
       " ' \\xa0',\n",
       " ' \\u1680',\n",
       " ' \\u2000',\n",
       " ' \\u2002',\n",
       " ' \\u2003',\n",
       " ' \\u2004',\n",
       " ' \\u2005',\n",
       " ' \\u2007',\n",
       " ' \\u2008',\n",
       " ' \\u200a',\n",
       " ' \\u2029',\n",
       " ' \\u202f',\n",
       " ' \\u3000',\n",
       " '!',\n",
       " '!!',\n",
       " '!!!',\n",
       " '!!!!',\n",
       " '!!!!!!!!!!!!!!!!',\n",
       " '!!!!.',\n",
       " '!!.',\n",
       " '!!?',\n",
       " '!!??',\n",
       " '!!|',\n",
       " '!*',\n",
       " '!,I',\n",
       " '!.',\n",
       " '!64',\n",
       " '!?',\n",
       " '!??',\n",
       " '!It',\n",
       " '!We',\n",
       " '!be',\n",
       " '!nk',\n",
       " '\"',\n",
       " '\"\"',\n",
       " '\"\"I',\n",
       " '\"\"The',\n",
       " '\"\"X',\n",
       " '\"\"Xxx',\n",
       " '\"\"i',\n",
       " '\"\"the',\n",
       " '\"(as',\n",
       " '\"(xx',\n",
       " '\"-',\n",
       " '\"--',\n",
       " '\"1',\n",
       " '\"2',\n",
       " '\"3',\n",
       " '\"4',\n",
       " '\"</p',\n",
       " '\"</p><p',\n",
       " '\"</x',\n",
       " '\"</x><x',\n",
       " '\"A',\n",
       " '\"And',\n",
       " '\"As',\n",
       " '\"But',\n",
       " '\"Credit',\n",
       " '\"D.',\n",
       " '\"FL',\n",
       " '\"For',\n",
       " '\"He',\n",
       " '\"I',\n",
       " '\"I\\'m',\n",
       " '\"II',\n",
       " '\"If',\n",
       " '\"In',\n",
       " '\"It',\n",
       " '\"June',\n",
       " '\"May',\n",
       " '\"Me',\n",
       " '\"My',\n",
       " '\"No',\n",
       " '\"Oh',\n",
       " '\"On',\n",
       " '\"Pa',\n",
       " '\"She',\n",
       " '\"That',\n",
       " '\"The',\n",
       " '\"There',\n",
       " '\"They',\n",
       " '\"This',\n",
       " '\"To',\n",
       " '\"Us',\n",
       " '\"WWW',\n",
       " '\"We',\n",
       " '\"What',\n",
       " '\"When',\n",
       " '\"X',\n",
       " '\"X\\'x',\n",
       " '\"XXX',\n",
       " '\"Xx',\n",
       " '\"Xxx',\n",
       " '\"Xxxx',\n",
       " '\"Xxxxx',\n",
       " '\"You',\n",
       " '\"[1',\n",
       " '\"[10',\n",
       " '\"[11',\n",
       " '\"[12',\n",
       " '\"[2',\n",
       " '\"[3',\n",
       " '\"[4',\n",
       " '\"[5',\n",
       " '\"[6',\n",
       " '\"[7',\n",
       " '\"[8',\n",
       " '\"[9',\n",
       " '\"[d',\n",
       " '\"[dd',\n",
       " '\"a',\n",
       " '\"am',\n",
       " '\"and',\n",
       " '\"as',\n",
       " '\"but',\n",
       " '\"credit',\n",
       " '\"d',\n",
       " '\"en',\n",
       " '\"for',\n",
       " '\"he',\n",
       " '\"i',\n",
       " '\"i\\'m',\n",
       " '\"if',\n",
       " '\"in',\n",
       " '\"it',\n",
       " '\"june',\n",
       " '\"ll',\n",
       " '\"may',\n",
       " '\"my',\n",
       " '\"on',\n",
       " '\"re',\n",
       " '\"rm',\n",
       " '\"s',\n",
       " '\"she',\n",
       " '\"that',\n",
       " '\"the',\n",
       " '\"there',\n",
       " '\"they',\n",
       " '\"this',\n",
       " '\"to',\n",
       " '\"ve',\n",
       " '\"we',\n",
       " '\"what',\n",
       " '\"when',\n",
       " '\"www',\n",
       " '\"x',\n",
       " '\"you',\n",
       " '\"\\x9d',\n",
       " '\"\\u200b',\n",
       " '#',\n",
       " \"##'s\",\n",
       " \"##'x\",\n",
       " '#$%',\n",
       " \"#'s\",\n",
       " '#15',\n",
       " '#39',\n",
       " '#^%',\n",
       " '#dd',\n",
       " '$',\n",
       " '$10',\n",
       " '$14',\n",
       " '$15',\n",
       " '$18',\n",
       " '$19',\n",
       " '$20',\n",
       " '$30',\n",
       " '$50',\n",
       " '$75',\n",
       " '$Whose',\n",
       " '$Xxxxx',\n",
       " '$ha',\n",
       " '$whose',\n",
       " '$xxxx',\n",
       " '%',\n",
       " '%-3',\n",
       " '%29',\n",
       " '%2C',\n",
       " '%2F',\n",
       " '%3A',\n",
       " '%CI',\n",
       " '%ach',\n",
       " '%ah',\n",
       " '%eh',\n",
       " '%er',\n",
       " '%ha',\n",
       " '%hm',\n",
       " '%huh',\n",
       " '%mm',\n",
       " '%oof',\n",
       " '%pw',\n",
       " '%uh',\n",
       " '%um',\n",
       " '%xx',\n",
       " '%xxx',\n",
       " '&',\n",
       " '&#',\n",
       " '&39',\n",
       " '&A.',\n",
       " '&AD',\n",
       " '&AW',\n",
       " '&As',\n",
       " '&B.',\n",
       " '&BR',\n",
       " '&Bs',\n",
       " '&C.',\n",
       " '&CK',\n",
       " '&CR',\n",
       " '&CS',\n",
       " '&Co',\n",
       " '&Cs',\n",
       " '&D.',\n",
       " '&DR',\n",
       " '&E.',\n",
       " '&ED',\n",
       " '&ER',\n",
       " '&Es',\n",
       " '&F.',\n",
       " '&FS',\n",
       " '&G.',\n",
       " '&GN',\n",
       " '&GR',\n",
       " '&GS',\n",
       " '&H.',\n",
       " '&ID',\n",
       " '&K.',\n",
       " '&L.',\n",
       " '&LE',\n",
       " '&LR',\n",
       " '&Ls',\n",
       " '&M.',\n",
       " '&MA',\n",
       " '&MR',\n",
       " '&Ms',\n",
       " '&NW',\n",
       " '&OD',\n",
       " '&OP',\n",
       " '&Os',\n",
       " '&P.',\n",
       " '&PI',\n",
       " '&Q.',\n",
       " '&R.',\n",
       " '&RG',\n",
       " '&Rs',\n",
       " '&S.',\n",
       " '&SA',\n",
       " '&SF',\n",
       " '&SR',\n",
       " '&T.',\n",
       " '&Ts',\n",
       " '&W.',\n",
       " '&WR',\n",
       " '&YR',\n",
       " '&ex',\n",
       " '&in',\n",
       " '&ls',\n",
       " '&of',\n",
       " '&on',\n",
       " '&sa',\n",
       " '&the',\n",
       " '&to',\n",
       " '&uh',\n",
       " '&von',\n",
       " '&xx',\n",
       " '&xxx',\n",
       " \"'\",\n",
       " \"''\",\n",
       " \"''It\",\n",
       " \"''M\",\n",
       " \"''T\",\n",
       " \"''Xx\",\n",
       " \"''d\",\n",
       " \"''it\",\n",
       " \"''m\",\n",
       " \"''t\",\n",
       " \"''xx\",\n",
       " \"'-(\",\n",
       " \"'-)\",\n",
       " \"'--\",\n",
       " \"'-O\",\n",
       " \"'03\",\n",
       " \"'07\",\n",
       " \"'10\",\n",
       " \"'11\",\n",
       " \"'20s\",\n",
       " \"'30s\",\n",
       " \"'40s\",\n",
       " \"'45\",\n",
       " \"'46\",\n",
       " \"'50s\",\n",
       " \"'60s\",\n",
       " \"'67\",\n",
       " \"'68\",\n",
       " \"'69\",\n",
       " \"'70's\",\n",
       " \"'70s\",\n",
       " \"'71\",\n",
       " \"'73\",\n",
       " \"'74\",\n",
       " \"'76\",\n",
       " \"'78\",\n",
       " \"'80\",\n",
       " \"'80's\",\n",
       " \"'80s\",\n",
       " \"'82\",\n",
       " \"'86\",\n",
       " \"'89\",\n",
       " \"'90's\",\n",
       " \"'90s\",\n",
       " \"'91\",\n",
       " \"'94\",\n",
       " \"'96\",\n",
       " \"'97\",\n",
       " \"'98\",\n",
       " \"'99\",\n",
       " \"'AM\",\n",
       " \"'AP\",\n",
       " \"'Al\",\n",
       " \"'Arabi\",\n",
       " \"'As\",\n",
       " \"'Av\",\n",
       " \"'Cause\",\n",
       " \"'Connery\",\n",
       " \"'Cos\",\n",
       " \"'Coz\",\n",
       " \"'Cuz\",\n",
       " \"'EI\",\n",
       " \"'El\",\n",
       " \"'Eu\",\n",
       " \"'I\",\n",
       " \"'II\",\n",
       " \"'Id\",\n",
       " \"'If\",\n",
       " \"'Il\",\n",
       " \"'It\",\n",
       " \"'LL\",\n",
       " \"'Ll\",\n",
       " \"'Lo\",\n",
       " \"'M-\",\n",
       " \"'N\",\n",
       " \"'Nita\",\n",
       " \"'OL\",\n",
       " \"'OM\",\n",
       " \"'OR\",\n",
       " \"'Or\",\n",
       " \"'RE\",\n",
       " \"'Re\",\n",
       " \"'S\",\n",
       " \"'S-\",\n",
       " \"'SA\",\n",
       " \"'Sa\",\n",
       " \"'T\",\n",
       " \"'T.\",\n",
       " \"'The\",\n",
       " \"'UE\",\n",
       " \"'US\",\n",
       " \"'VE\",\n",
       " \"'Ve\",\n",
       " \"'Vi\",\n",
       " \"'X\",\n",
       " \"'Xx\",\n",
       " \"'Xxx\",\n",
       " \"'Xxxx\",\n",
       " \"'Xxxxx\",\n",
       " \"'ab\",\n",
       " \"'ad\",\n",
       " \"'ah\",\n",
       " \"'ai\",\n",
       " \"'al\",\n",
       " \"'am\",\n",
       " \"'amour\",\n",
       " \"'an\",\n",
       " \"'ao\",\n",
       " \"'ar\",\n",
       " \"'arabi\",\n",
       " \"'as\",\n",
       " \"'at\",\n",
       " \"'au\",\n",
       " \"'av\",\n",
       " \"'ay\",\n",
       " \"'ba\",\n",
       " \"'bout\",\n",
       " \"'cause\",\n",
       " \"'connery\",\n",
       " \"'cos\",\n",
       " \"'coz\",\n",
       " \"'cuz\",\n",
       " \"'d\",\n",
       " \"'d-\",\n",
       " \"'d.\",\n",
       " \"'da\",\n",
       " \"'dd\",\n",
       " \"'dd'x\",\n",
       " \"'ddx\",\n",
       " \"'di\",\n",
       " \"'droid\",\n",
       " \"'du\",\n",
       " \"'ed\",\n",
       " \"'eh\",\n",
       " \"'ei\",\n",
       " \"'el\",\n",
       " \"'em\",\n",
       " \"'en\",\n",
       " \"'er\",\n",
       " \"'es\",\n",
       " \"'ev\",\n",
       " \"'ex\",\n",
       " \"'ez\",\n",
       " \"'i\",\n",
       " \"'ib\",\n",
       " \"'id\",\n",
       " \"'if\",\n",
       " \"'ig\",\n",
       " \"'ii\",\n",
       " \"'ik\",\n",
       " \"'il\",\n",
       " \"'im\",\n",
       " \"'in\",\n",
       " \"'iq\",\n",
       " \"'ir\",\n",
       " \"'is\",\n",
       " \"'it\",\n",
       " \"'ja\",\n",
       " \"'ku\",\n",
       " \"'l\",\n",
       " \"'lI\",\n",
       " \"'la\",\n",
       " \"'le\",\n",
       " \"'li\",\n",
       " \"'ll\",\n",
       " \"'lo\",\n",
       " \"'lu\",\n",
       " \"'m\",\n",
       " \"'m-\",\n",
       " \"'ma\",\n",
       " \"'mm\",\n",
       " \"'n\",\n",
       " \"'n'\",\n",
       " \"'ni\",\n",
       " \"'nita\",\n",
       " \"'ns\",\n",
       " \"'nt\",\n",
       " \"'nuff\",\n",
       " \"'oh\",\n",
       " \"'on\",\n",
       " \"'or\",\n",
       " \"'où\",\n",
       " \"'rE\",\n",
       " \"'ra\",\n",
       " \"'re\",\n",
       " \"'recg\",\n",
       " \"'ri\",\n",
       " \"'ry\",\n",
       " \"'s\",\n",
       " \"'s**\",\n",
       " \"'s-\",\n",
       " \"'s_\",\n",
       " \"'sa\",\n",
       " \"'se\",\n",
       " \"'st\",\n",
       " \"'t\",\n",
       " \"'t-\",\n",
       " \"'th\",\n",
       " \"'the\",\n",
       " \"'ti\",\n",
       " \"'til\",\n",
       " \"'tm\",\n",
       " \"'to\",\n",
       " \"'ts\",\n",
       " \"'tt\",\n",
       " \"'ud\",\n",
       " \"'uh\",\n",
       " \"'un\",\n",
       " \"'up\",\n",
       " \"'vE\",\n",
       " \"'va\",\n",
       " \"'ve\",\n",
       " \"'vi\",\n",
       " \"'x\",\n",
       " \"'x'\",\n",
       " \"'x**\",\n",
       " \"'x8\",\n",
       " \"'xx\",\n",
       " \"'xxx\",\n",
       " \"'xxxx\",\n",
       " \"'y\",\n",
       " \"'ya\",\n",
       " \"'yō\",\n",
       " \"'||\",\n",
       " \"'ÉÉ\",\n",
       " \"'Ï\",\n",
       " \"'ís\",\n",
       " \"'ï\",\n",
       " \"'īn\",\n",
       " \"'νe\",\n",
       " '(',\n",
       " '(((',\n",
       " '(*>',\n",
       " '(*_*)',\n",
       " '(-1',\n",
       " '(-8',\n",
       " '(-:',\n",
       " '(-;',\n",
       " '(-_-)',\n",
       " '(-d',\n",
       " '(._.)',\n",
       " '(02)',\n",
       " '(10',\n",
       " '(:',\n",
       " '(;',\n",
       " '(=',\n",
       " '(>_<)',\n",
       " '(AM',\n",
       " '(A\\\\',\n",
       " '(I',\n",
       " '(II',\n",
       " '(ML',\n",
       " '(More',\n",
       " '(Read',\n",
       " '(VI',\n",
       " '(X',\n",
       " '(Xxxx',\n",
       " '(^_^)',\n",
       " '(am',\n",
       " '(and',\n",
       " '(as',\n",
       " '(c)?Ìö]o?',\n",
       " '(c)?ìö]o?',\n",
       " '(c)x',\n",
       " '(c)x˙goÌö',\n",
       " '(c)x˙goìö',\n",
       " '(dd)',\n",
       " '(es',\n",
       " '(f\\\\',\n",
       " '(hp',\n",
       " '(i',\n",
       " '(mm',\n",
       " '(more',\n",
       " '(n2',\n",
       " '(n\\\\',\n",
       " '(o:',\n",
       " '(read',\n",
       " '(tm',\n",
       " '(x)?Xx]x?',\n",
       " '(x)?xx]x?',\n",
       " '(x)x',\n",
       " '(x)x˙xxXx',\n",
       " '(x:',\n",
       " '(x\\\\',\n",
       " '(x_x)',\n",
       " '(xxx',\n",
       " '(xxxx',\n",
       " '(¬_¬)',\n",
       " '(ಠ_ಠ)',\n",
       " '(╯°□°）╯︵┻━┻',\n",
       " ')',\n",
       " \")'-\",\n",
       " ')(1',\n",
       " ')(2',\n",
       " ')(3',\n",
       " ')(4',\n",
       " ')(6',\n",
       " ')(a',\n",
       " ')(b',\n",
       " ')(c',\n",
       " ')(f',\n",
       " ')))',\n",
       " ')--',\n",
       " ')-:',\n",
       " ').-',\n",
       " ')/2',\n",
       " ')/¯',\n",
       " ')20',\n",
       " '):',\n",
       " ')P2',\n",
       " ')he',\n",
       " ')||',\n",
       " ')}I',\n",
       " ')}a',\n",
       " '*',\n",
       " '*$',\n",
       " '**',\n",
       " '***',\n",
       " '****',\n",
       " '*****',\n",
       " '*********',\n",
       " '**,',\n",
       " '**-',\n",
       " '**.',\n",
       " '**Anday**',\n",
       " '**Dougo',\n",
       " '**Dougo**',\n",
       " '**Eee**.',\n",
       " '**K',\n",
       " '**Mal**',\n",
       " '**Marchish**',\n",
       " '**X',\n",
       " '**Xxx**',\n",
       " '**Xxx**.',\n",
       " '**Xxxxx',\n",
       " '**Xxxxx**',\n",
       " '**Y',\n",
       " '**Yuh**',\n",
       " '**aimnay**',\n",
       " '**ainday**',\n",
       " '**anday**',\n",
       " '**arimay**',\n",
       " '**arimay**,',\n",
       " '**bisay**',\n",
       " '**bladyblah**',\n",
       " '**cooky**',\n",
       " '**d',\n",
       " '**doroter**.',\n",
       " '**dougo',\n",
       " '**dougo**',\n",
       " '**e',\n",
       " '**eee**.',\n",
       " '**g',\n",
       " '**h',\n",
       " '**ick**',\n",
       " '**icky**',\n",
       " '**junkmobile**',\n",
       " '**k',\n",
       " '**luch**',\n",
       " '**mal**',\n",
       " '**marchish**',\n",
       " '**maturer**',\n",
       " '**oray**,',\n",
       " '**ouchies**',\n",
       " '**ouchies**,',\n",
       " '**p',\n",
       " '**pammy**',\n",
       " '**pep**',\n",
       " '**piccy**',\n",
       " '**putty',\n",
       " '**r',\n",
       " '**ruthie**',\n",
       " '**s',\n",
       " '**shpritz**',\n",
       " '**staticky**',\n",
       " '**switcheroony**',\n",
       " '**t',\n",
       " '**thingy**',\n",
       " '**touristy**',\n",
       " '**uptay**',\n",
       " '**uyay**,',\n",
       " '**x',\n",
       " '**xxx**',\n",
       " '**xxx**.',\n",
       " '**xxxx',\n",
       " '**xxxx**',\n",
       " '**xxxx**,',\n",
       " '**xxxx**.',\n",
       " '**y',\n",
       " '**yuh**',\n",
       " '*-C',\n",
       " '*1',\n",
       " '*2',\n",
       " '*3',\n",
       " '*4',\n",
       " '*H.',\n",
       " '*ch',\n",
       " '*ck',\n",
       " '*d',\n",
       " '*ed',\n",
       " '*in',\n",
       " '*integrated',\n",
       " '*require*',\n",
       " '*when*',\n",
       " '*xxxx',\n",
       " '*xxxx*',\n",
       " '+',\n",
       " '+++',\n",
       " '+.ﾟ',\n",
       " '+/+',\n",
       " '+0',\n",
       " '+0.1',\n",
       " '+0.2',\n",
       " '+0.3',\n",
       " '+0.4',\n",
       " '+0.5',\n",
       " '+0.6',\n",
       " '+0.7',\n",
       " '+0.8',\n",
       " '+0.9',\n",
       " '+0000',\n",
       " '+0000Africa',\n",
       " '+0000africa',\n",
       " '+01',\n",
       " '+0100',\n",
       " '+0100Africa',\n",
       " '+0100Europe',\n",
       " '+0100africa',\n",
       " '+0100europe',\n",
       " '+0200',\n",
       " '+0200Africa',\n",
       " '+0200Europe',\n",
       " '+0200africa',\n",
       " '+0200europe',\n",
       " '+0500Asia',\n",
       " '+0500asia',\n",
       " '+0530',\n",
       " '+0700Asia',\n",
       " '+0700asia',\n",
       " '+0800Asia',\n",
       " '+0800asia',\n",
       " '+1',\n",
       " '+1)\\u200e',\n",
       " '+1.0',\n",
       " '+1.1',\n",
       " '+1.2',\n",
       " '+1.3',\n",
       " '+1.4',\n",
       " '+1.5',\n",
       " '+1.6',\n",
       " '+1.7',\n",
       " '+1.8',\n",
       " '+1.9',\n",
       " '+1/+1',\n",
       " '+10',\n",
       " '+100',\n",
       " '+1000',\n",
       " '+105',\n",
       " '+11',\n",
       " '+110',\n",
       " '+12',\n",
       " '+120',\n",
       " '+125',\n",
       " '+12V',\n",
       " '+12v',\n",
       " '+13',\n",
       " '+130',\n",
       " '+14',\n",
       " '+15',\n",
       " '+150',\n",
       " '+16',\n",
       " '+17',\n",
       " '+18',\n",
       " '+19',\n",
       " '+1\\u200e',\n",
       " '+2',\n",
       " '+2)\\u200e',\n",
       " '+2.0',\n",
       " '+2.1',\n",
       " '+2.2',\n",
       " '+2.3',\n",
       " '+2.4',\n",
       " '+2.5',\n",
       " '+2.6',\n",
       " '+20',\n",
       " '+200',\n",
       " '+21',\n",
       " '+22',\n",
       " '+23',\n",
       " '+233',\n",
       " '+234',\n",
       " '+24',\n",
       " '+25',\n",
       " '+250',\n",
       " '+254',\n",
       " '+26',\n",
       " '+263',\n",
       " '+27',\n",
       " '+28',\n",
       " '+29',\n",
       " '+3',\n",
       " '+3.3',\n",
       " '+3.5',\n",
       " '+30',\n",
       " '+300',\n",
       " '+31',\n",
       " '+32',\n",
       " '+33',\n",
       " '+34',\n",
       " '+35',\n",
       " '+350',\n",
       " '+351',\n",
       " '+353',\n",
       " '+356',\n",
       " '+358',\n",
       " '+36',\n",
       " '+37',\n",
       " '+38',\n",
       " ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nlp.vocab.strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(texts, max_vocab=10000, min_freq=3):\n",
    "    nlp_ = spacy.blank(\"en\") # just the tokenizer\n",
    "    wc = Counter()\n",
    "    for doc in nlp_.pipe(texts):\n",
    "        for word in doc:\n",
    "            wc[word.lower_] += 1\n",
    "\n",
    "    word2id = {}\n",
    "    id2word = {}\n",
    "    for word, count in wc.most_common():\n",
    "        if count < min_freq: break\n",
    "        if len(word2id) >= max_vocab: break\n",
    "        wid = len(word2id)\n",
    "        word2id[word] = wid\n",
    "        id2word[wid] = word\n",
    "    return word2id, id2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"../data/train.csv\")\n",
    "df_train = df_train.sample(frac = 1)\n",
    "train_data = df_train['text'].to_numpy()\n",
    "\n",
    "vocab_size = 5000 # params\n",
    "oov_tok = '<OOV>'\n",
    "\n",
    "# tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "# tokenizer.fit_on_texts(train_data)\n",
    "\n",
    "# train_sequences = tokenizer.texts_to_sequences(train_data)\n",
    "\n",
    "# max_length = 50 # params\n",
    "# trunc_type = 'post'\n",
    "# padding_type = 'post'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id, id2word = build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project_finbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
